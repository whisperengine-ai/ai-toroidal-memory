//! Large-scale GPU Benchmark: Test performance on massive grids
//!
//! Run with: cargo run --example gpu_benchmark_large --features gpu --release

#[cfg(feature = "gpu")]
use ai_toroidal_memory::GpuDiffusionEngine;
use ai_toroidal_memory::{DiffusionEngine, DiffusionConfig, ToroidalMemory};
use std::time::Instant;

fn benchmark_cpu(width: usize, height: usize, steps: usize) -> f64 {
    println!("\n  CPU Benchmark: {}x{} grid, {} steps", width, height, steps);
    
    let mut memory = ToroidalMemory::new(width, height);
    
    // Initialize with pattern
    for y in 0..height {
        for x in 0..width {
            let value = ((x + y) as f64 % 10.0) / 10.0;
            memory.set(x as isize, y as isize, value);
        }
    }
    
    let config = DiffusionConfig {
        diffusion_rate: 0.1,
        decay_rate: 0.05,
        threshold: 0.1,
    };
    
    let engine = DiffusionEngine::new(config);
    
    let start = Instant::now();
    for _ in 0..steps {
        memory = engine.step(&memory);
    }
    let elapsed = start.elapsed().as_secs_f64();
    
    println!("    âœ“ Completed in {:.4}s ({:.1} steps/sec)", 
             elapsed, steps as f64 / elapsed);
    
    elapsed
}

#[cfg(feature = "gpu")]
async fn benchmark_gpu(width: usize, height: usize, steps: usize) -> f64 {
    println!("\n  GPU Benchmark: {}x{} grid, {} steps", width, height, steps);
    
    let mut gpu = match GpuDiffusionEngine::new(width, height, 0.1, 0.05, 0.1).await {
        Ok(g) => g,
        Err(e) => {
            println!("    âœ— GPU initialization failed: {}", e);
            return 0.0;
        }
    };
    
    // Initialize with pattern
    let mut data = vec![0.0; width * height];
    for y in 0..height {
        for x in 0..width {
            data[y * width + x] = ((x + y) as f32 % 10.0) / 10.0;
        }
    }
    
    gpu.upload_data(&data).await.ok();
    
    let start = Instant::now();
    for _ in 0..steps {
        gpu.diffusion_step().await.ok();
    }
    let elapsed = start.elapsed().as_secs_f64();
    
    println!("    âœ“ Completed in {:.4}s ({:.1} steps/sec)", 
             elapsed, steps as f64 / elapsed);
    
    elapsed
}

#[cfg(not(feature = "gpu"))]
async fn benchmark_gpu(_width: usize, _height: usize, _steps: usize) -> f64 {
    println!("\n  GPU Benchmark: SKIPPED (compile with --features gpu)");
    0.0
}

#[tokio::main]
async fn main() {
    println!("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
    println!("â•‘         Large-Scale GPU Benchmark                          â•‘");
    println!("â•‘         Apple Silicon Performance on Massive Grids         â•‘");
    println!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    
    // Test cases: larger grids to show GPU advantage
    let test_cases = vec![
        (256, 256, 20, "256x256 - Small GPU workload"),
        (512, 512, 10, "512x512 - Medium GPU workload"),
        (1024, 1024, 5, "1024x1024 - Large GPU workload"),
        (2048, 2048, 2, "2048x2048 - Massive GPU workload"),
    ];
    
    println!("\nðŸš€ Large-scale diffusion benchmarks:\n");
    
    let mut results = Vec::new();
    
    for (width, height, steps, description) in test_cases {
        println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
        println!("Test: {}", description);
        println!("Grid Size: {}x{} ({} cells)", width, height, width * height);
        
        let cpu_time = benchmark_cpu(width, height, steps);
        let gpu_time = benchmark_gpu(width, height, steps).await;
        
        if gpu_time > 0.0 {
            let speedup = cpu_time / gpu_time;
            println!("  \n  âš¡ Speedup: {:.2}x", speedup);
            
            // Calculate throughput
            let total_cells = (width * height * steps) as f64;
            let cpu_throughput = total_cells / cpu_time / 1_000_000.0;  // Million cells/sec
            let gpu_throughput = total_cells / gpu_time / 1_000_000.0;
            
            println!("  CPU Throughput: {:.1} M cells/sec", cpu_throughput);
            println!("  GPU Throughput: {:.1} M cells/sec", gpu_throughput);
            
            results.push((description, speedup));
        }
    }
    
    println!("\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    println!("\nðŸ“Š Summary of Large-Scale Performance:\n");
    
    for (desc, speedup) in results {
        let status = if speedup > 10.0 { "ðŸ”¥ Excellent" } 
                     else if speedup > 5.0 { "âš¡ Very Good" }
                     else if speedup > 2.0 { "âœ“ Good" }
                     else { "â„¹ Modest" };
        
        println!("  {}: {:.2}x ({} speedup)", desc, speedup, status);
    }
    
    println!("\nðŸ’¡ Key Insights:");
    println!("  â€¢ GPU excels on massive grids (1024Ã—1024+)");
    println!("  â€¢ Speedup increases with grid size");
    println!("  â€¢ Metal backend efficiently parallelizes diffusion");
    println!("  â€¢ Throughput scales to millions of cells/sec");
}
